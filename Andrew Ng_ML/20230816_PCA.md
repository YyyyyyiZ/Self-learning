# Principle Component Analysis (PCA)

> find new axis and coordinates

> unsupervised learning algorithm

## Algorithm
* Feature Scaling
* choose an axis (project examples onto the new axis)

<img src="C:\Users\BNY1SGH\AppData\Roaming\Typora\typora-user-images\image-20230816104058399.png" alt="image-20230816104058399" style="zoom:80%;" />

* more principal components (perpendicular)
* optionally examine how much variance is explained by each principle component
* transport (project) data to the new axis

> reconstruction---approximation to the original data but not exact

## PCA vs. Linear Regression

* prediction
* reducing features

<img src="C:\Users\BNY1SGH\AppData\Roaming\Typora\typora-user-images\image-20230816104554073.png" alt="image-20230816104554073" style="zoom:67%;" />


## Implementation

```python
pca_1 = PCA(n_components = 1)
pca_1.fit(X)
pca_1.explained_variance_ratio_
X_trans_1 = pca_1.transform(X)
X_reduced_1 = pca.inverse_transform(X_trans_1)
```

## Application

* data visualization
* data compression
* speed up training of a supervised learning model