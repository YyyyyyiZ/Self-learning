# Sequence to Sequence Models

## Basic models

* machine translation
	* can be understood as conditional language model
	* RNN, encode and decode

* image captioning
	* AlexNet $\to$ RNN

## Machine translation

### why not a greedy research

* It’s not optimal to pick just one word at a time, redundancy and exponentially large

### Beam Search

> compared with BFS/DFS, BS runs faster but is not guaranteed to find exact maximun

* $B$—beam width
	* the larger, the more computational cost

#### Length Normalization

$$
arg\ \underset{y}{max}\prod\limits_{i=1}^{T_y}P(x,y^{<1>},...,y^{<t-1>})\\=P(y^{<1>}|x)P(y^{<2>}|x,y^{<1>})...P(y^{<T_y>}|x,y^{<1>}...y^{<T_y-1>})
$$

* In Practice


$$
arg\ \underset{y}{max}\sum\limits_{i=1}^{T_y}logP(x,y^{<1>},...,y^{<t-1>})
$$

* disadvantage
	* unnaturally tends to prefer short translations

$$
\frac{1}{T_y^\alpha}\sum\limits_{i=1}^{T_y}logP(x,y^{<1>},...,y^{<t-1>})
$$

#### Error analysis on BS

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230809091331041.png" alt="image-20230809091331041" style="zoom:50%;" />

### BLEU score

> bilingual evaluation

> measure how good the translation is

## Attention Model[^1]

### Intuition

* The problem of long sequences

[^1]:  Bahdanau et al., 2014. Neural machine translation by jointly learning to align and translate

* attention weight
	* what context should be paied attention to

### Implementation

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230809183851532.png" alt="image-20230809183851532" style="zoom:50%;" />

### Speech Recognition

#### CTC(connectionist temporal classification) cost

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230809184946386.png" alt="image-20230809184946386" style="zoom:67%;" />

#### Trigger word detection

# Transformer Network

> $A(q,K,V)=$ create attention-based vector representation of a word

* Attention+CNN
	* Self-Attention
	* Multi-Head Attention

### Self-Attention

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230809191522326.png" alt="image-20230809191522326" style="zoom:50%;" />

* q—a question about what is happening in that word
* k—how similar other word is to the query, which word gives the most relevant answer to the question
* v—allow the representation to plug in how each word should be represented in the attention

### Multi-Head Attention

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230809192505544.png" alt="image-20230809192505544" style="zoom:50%;" />

### Transformer

#### Positioning Embedding

