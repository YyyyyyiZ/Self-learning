# NLP

## Word representation

### one-hot

### Featurized representation: word embedding

#### Transfer learning

* learn word embeddings from large text corpus(1-100B words) or download pre-trained embedding online
* transfer embedding to new task with smaller training set (100k words)
* optional: continue to fine-tune the word embedding with the new data

#### Relation to face encoding (Siamense)

#### Properties

* analogy reasoning

#### Similarity function

* cosinre similarity
* square distance

#### Embedding matrix

> individual rows not intepretable

#### Word2Vec algo

* **skip-gram**

	* context $c\to$ target $t$

	* softmax classification

	* computational speed, can be improved by hierachical softmax

* **negative sampling**

	* create a new unsupervised learning problem
	* turn n softmax classifcation into n binary classification

	<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230808202743377.png" alt="image-20230808202743377" style="zoom:50%;" />

* **GloVe (gloal vectors for word representation)**
	* (context $c$, target $t$)
	* $x_{ij}$ = # times i (c) appears in the context of j (t)

### Debias word embeddings

* word embeddings can reflect gender, ethnicity, age, sexual orientation and other biases of the ==text used to train the model==
* address
	* identify bias direction
	* neutralize: for every word that is not definational, poject to get rid of bias
	* equalize pairs

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230808205750182.png" alt="image-20230808205750182" style="zoom:50%;" />

## Sentiment Classification

### Simple model

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230808204731253.png" alt="image-20230808204731253" style="zoom:50%;" />

### RNN for sentiment classification

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230808204911987.png" alt="image-20230808204911987" style="zoom:50%;" />
