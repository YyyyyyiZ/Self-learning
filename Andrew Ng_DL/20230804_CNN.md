# Computer Vision

## Edge detection

### Vertical Edge Detection

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230804101203828.png" alt="image-20230804101203828" style="zoom:50%;" />

### More Edge Detection

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230804101559118.png" alt="image-20230804101559118" style="zoom:50%;" />

## Padding

> pixels on the corners or on the edges are used much less in the output

* pad the image
* valid convolution: no padding

$$
n×n\ *\ f×f\to n-f+1×n-f+1
$$

* same convolution: output size is the same of the input size

$$
n+2p-f+1×n+2p-f+1\ *\ f×f\to n×n\\
p=\frac{f-1}{2}
$$

## Strided Convolution

$$
\lfloor \frac{n+2p-f}{s}+1\rfloor*\lfloor \frac{n+2p-f}{s}+1\rfloor
$$

## 3D Convolution

* height
* width
* number of channels/d
* multiple filters

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230804104251881.png" alt="image-20230804104251881" style="zoom:50%;" />

## ConvNet

* Convolution (CONV)

$$
n^{[l]}=\lfloor \frac{n^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\rfloor\\
a^{[l]}=n_H^{[l]}×n_W^{[l]}×n_C^{[l]}\\
w^{[l]} = f^{[l]}×f^{[l]}×n_C^{[l-1]}×n_C^{[l]}\\
b^{[l]}=n_C^{[l]}
$$

* Pooling (PL)—==no parameters==
	* Max pooling
	* Average pooling
* Fully connected (FC)

![LeNet-5](https://img-blog.csdnimg.cn/img_convert/ff7818be02f52eb088b1b114f664cf2b.png)

<img src="C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20230806081557187.png" alt="image-20230806081557187" style="zoom:50%;" />

## Why convolutions

* parameter sharing
	* a feature detector that’s useful in one part of the image is probably useful in another part of the image
* sparsity of connections
	* In each layer, each output valu depends only on a small number of inputs
